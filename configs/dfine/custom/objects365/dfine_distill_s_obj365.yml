__include__: [
  '../../../dataset/baseline2-background-syn-1-1.yml',
  '../../../runtime.yml',
  '../../include/dataloader_640.yml',
  '../../include/optimizer.yml',
  '../../include/dfine_hgnetv2_640.yml',
]

output_dir: ./dfine_s_distill

use_distillation: True

teacher_model_config_path: /workspace/Repos/Enn/Chill_3/configs/dfine/custom/objects365/baseline2-background.yml

teacher_model_weights_path: /workspace/Repos/maibel/D-FINE/output/baseline2-background/checkpoint0074.pth


DFINE:
  backbone: HGNetv2

HGNetv2:
  name: 'B0'
  return_idx: [1, 2, 3]
  freeze_at: -1
  freeze_norm: False
  use_lab: True
  pretrained: False

DFINETransformer:
  num_layers: 3  # 4 5 6
  eval_idx: -1  # -2 -3 -4

HybridEncoder:
  in_channels: [256, 512, 1024]
  hidden_dim: 256
  depth_mult: 0.34
  expansion: 0.5

optimizer:
  type: AdamW
  params:
    -
      params: '^(?=.*backbone)(?!.*norm|bn).*$'
      lr: 0.00003125
    -
      params: '^(?=.*backbone)(?=.*norm|bn).*$'
      lr: 0.00003125
      weight_decay: 0.
    -
      params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn|bias)).*$'
      weight_decay: 0.

  lr: 0.0000625
  betas: [0.9, 0.999]
  weight_decay: 0.000125


epochs: 80 # Early stop
train_dataloader:
  dataset:
    transforms:
      policy:
        epoch: 76
  collate_fn:
    stop_epoch: 76
    ema_restart_decay: 0.9999
    base_size_repeat: 10

ema:
  warmups: 0

lr_warmup_scheduler:
  warmup_duration: 0
